# higlass-server

The HiGlass Server supports the [HiGlass Client](https://github.com/hms-dbmi/higlass)
by providing APIs for accessing and uploading tile files generated by
[Clodius](https://github.com/hms-dbmi/clodius).

## Easy Docker install

The easiest way to run HiGlass is with Docker. More information is available at
[higlass-docker](https://github.com/hms-dbmi/higlass-docker#readme).

## Installation from source

```bash
git clone https://github.com/hms-dbmi/higlass-server.git
cd higlass-server/
pip install --upgrade -r requirements.txt
python manage.py migrate
python manage.py runserver localhost:8000
```

(Note that this server does not provide any HTML,
so visiting http://localhost:8000/ only produces a 404.)

## API Demo

A username and password are required for most API calls. For now, the best way to do this is:
```
echo "import django.contrib.auth; django.contrib.auth.models.User.objects.create_user('username', password='password')" \
     | python manage.py shell
```

```
COOLER=dixon2012-h1hesc-hindiii-allreps-filtered.1000kb.multires.cool
HITILE=wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.hitile

wget -P /tmp https://s3.amazonaws.com/pkerp/public/$COOLER
wget -P /tmp https://s3.amazonaws.com/pkerp/public/$HITILE

curl -F "datafile=@/tmp/$COOLER" -F "filetype=cooler" -F "datatype=matrix" -F "uid=cooler-demo" \
     -u username:password -F "coordSystem=hg19" http://localhost:8000/api/v1/tilesets/
curl -F "datafile=@/tmp/$HITILE" -F "filetype=hitile" -F "datatype=vector" -F "uid=hitile-demo" \
     -u username:password -F "coordSystem=hg19" http://localhost:8000/api/v1/tilesets/
```

The `uid` parameter is optional, and if it were missing, one would be generated.
Each POST returns JSON describing the new object.

We can now use the API to get information about a tileset:
```
curl http://localhost:8000/api/v1/tileset_info/?d=hitile-demo
```

Or to get a tile:
```
curl http://localhost:8000/api/v1/tiles/?d=hitile-demo.0.0.0
```

### Preparing cooler files for use with `higlass-server`

[Cooler](https://github.com/mirnylab/cooler) files store Hi-C data. They need to be decorated with aggregated data at multiple resolutions in order to work with `higlass-server`.
This is easily accomplished by simply installing the `cooler` python package and running the `recursive_agg_onefile.py` script. For now this has to come from a clone of the
official cooler repository, but this will hopefully be merged into the main branch shortly.

```

git clone -b develop https://github.com/pkerpedjiev/cooler.git
cd cooler
python setup.py install

recursive_agg_onefile.py file.cooler --out output.cooler
```

### Preparing bigWig files for use with `higlass-server`

[BigWig](https://genome.ucsc.edu/goldenpath/help/bigWig.html) files contain values for positions along a genome. To be viewable using higlass, they need to be aggregated using `clodius`:

Installing `clodius`:

```
pip install clodius
```

Getting a sample dataset:

```
wget http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeCaltechRnaSeq/wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.bigWig
```

Aggregate it:

```
tile_bigWig.py wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.bigWig --output-file data/wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.hitile
```

Register it:

```
curl -H "Content-Type: application/json" -X POST -d '{"processed_file":"data/wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2","file_type":"hitile"}' http://localhost:8000/tilesets/
```

### Registering a cooler file

See the "Add a dataset" line in the "Jump Start" section above.

### Unit tests

```
wget -O -P data/ https://s3.amazonaws.com/pkerp/public/dixon2012-h1hesc-hindiii-allreps-filtered.1000kb.multires.cool
wget -O -P data/ https://s3.amazonaws.com/pkerp/public/wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.hitile
wget -O -P data/ https://s3.amazonaws.com/pkerp/public/gene_annotations.short.db

python manage.py test tilesets
```

### Upgrade

```
bumpversion patch
```
